{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "material-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from networks import SegNet\n",
    "\n",
    "# Constant variables\n",
    "EPOCHS = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.001\n",
    "INPUT_CHANNELS = 3\n",
    "OUTPUT_CHANNELS = 13\n",
    "IMG_SIZE = (288, 384)\n",
    "# Paths\n",
    "\n",
    "TRAIN_RGB_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/train_rgb/\"\n",
    "TRAIN_SEG_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/train_seg13/\"\n",
    "\n",
    "TEST_RGB_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/test_rgb/\"\n",
    "TEST_SEG_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/test_seg13/\"\n",
    "\n",
    "CHECKPOINT_DIR = '/home/shubham/MTML_Pth/checkpoints/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premium-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(flag):\n",
    "    \"\"\"\n",
    "    returns dictionary of images and their corresponding annotations split into train, val and test\n",
    "    :params: flag - (task) segmentation, depth or surface normal\n",
    "    \"\"\" \n",
    "    data = {}\n",
    "    label = {}\n",
    "    \n",
    "    TRAIN_PATH_IMG = None\n",
    "    TRAIN_PATH_LAB = None\n",
    "    TEST_PATH_IMG = None\n",
    "    TEST_PATH_LAB = None\n",
    "    \n",
    "    if flag == \"segmentation\":\n",
    "        TRAIN_PATH_IMG =  TRAIN_RGB_PATH\n",
    "        TRAIN_PATH_LAB = TRAIN_SEG_PATH\n",
    "        TEST_PATH_IMG = TEST_RGB_PATH\n",
    "        TEST_PATH_LAB = TEST_SEG_PATH\n",
    "        \n",
    "    elif flag == \"depth\":\n",
    "        TRAIN_PATH_IMG = None\n",
    "        TRAIN_PATH_LAB = None # fill in later\n",
    "        \n",
    "    train_images = glob.glob(TRAIN_PATH_IMG + \"*.png\")\n",
    "    train_labels = glob.glob(TRAIN_PATH_LAB + \"*.png\")\n",
    "    \n",
    "    index = np.random.permutation(len(train_images))\n",
    "    images = np.array(train_images)[index]\n",
    "    labels = np.array(train_labels)[index]\n",
    "    \n",
    "    length = int(len(images)*0.85)\n",
    "   \n",
    "    data[\"train\"], data[\"val\"] = images[:length], images[length:]\n",
    "    label[\"train\"], label[\"val\"] = labels[:length], labels[length:]\n",
    "    data[\"test\"] = glob.glob(TEST_PATH_IMG + \"*.png\")\n",
    "    label[\"test\"] = glob.glob(TEST_PATH_LAB + \"*.png\")\n",
    "    \n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extraordinary-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, data, ground_truth, transform = None):\n",
    "        self.data = data\n",
    "        self.gt = ground_truth\n",
    "        self.length = len(data)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx])\n",
    "        img = img.resize(IMG_SIZE, Image.BILINEAR)\n",
    "        img = np.array(img)\n",
    "        gt = Image.open(self.gt[idx])\n",
    "        gt = gt.resize(IMG_SIZE, Image.BILINEAR)\n",
    "        gt = np.array(gt)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alone-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, tloader, vloader, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    returns loss and accuracy of the model for 1 epoch.\n",
    "    params: model -  vgg16\n",
    "          tloader - train dataset\n",
    "          vloader - val dataset\n",
    "          criterion - loss function\n",
    "          optimizer - Adam optimizer\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    t_epoch_accuracy = 0\n",
    "\n",
    "    v_epoch_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for ind, (image, label) in enumerate(tloader):\n",
    "     \n",
    "        image = image.to(DEVICE)\n",
    "        label = label.type(torch.LongTensor)\n",
    "        label = label.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _= model(image)\n",
    "        print(output.shape, type(output), label.shape, type(label))\n",
    "        loss = criterion(output, label)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    t_epoch_loss = np.average(train_losses)\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ind, (image, label) in enumerate(vloader):\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.type(torch.LongTensor)\n",
    "            label = label.to(DEVICE)\n",
    "            output,_ = model(image)\n",
    "            loss = criterion(output, label)\n",
    "            valid_losses.append(loss.item())\n",
    "    \n",
    "    \n",
    "    v_epoch_loss = np.average(valid_losses)\n",
    "        \n",
    "    \n",
    "    return t_epoch_loss, v_epoch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broadband-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainloader, valloader):\n",
    "    \"\"\"\n",
    "    returns losses (train and val), accuracies (train and val), trained_model\n",
    "    params: trainloader = train dataset\n",
    "            valloader = validation dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    model = SegNet(INPUT_CHANNELS, OUTPUT_CHANNELS).to(DEVICE)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"Running Epoch {}\".format(epoch+1))\n",
    "\n",
    "        epoch_train_loss,  epoch_val_loss = train_loop(model, trainloader, valloader, criterion, optimizer)\n",
    "        train_loss.append(epoch_train_loss)   \n",
    "        val_loss.append(epoch_val_loss)\n",
    "  \n",
    "\n",
    "        print(\"Training loss: {:.4f}\".format(epoch_train_loss))\n",
    "        print(\"Validation loss: {:.4f}\".format(epoch_val_loss))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "        if (epoch+1)%5 == 0:\n",
    "            torch.save(model.state_dict(), CHECKPOINT_DIR + \"/segnet_epoch_\" + str(epoch+1) + \".pth\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    losses = [train_loss, val_loss]\n",
    "    accuracies = [train_acc, val_acc]\n",
    "    \n",
    "    return losses, accuracies, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sustained-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, testloader):\n",
    "    \"\"\"\n",
    "    returns performance of the model on test dataset\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ind, (image, label) in enumerate(testloader):\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE, dtype=torch.long)\n",
    "\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted==label).sum().item()\n",
    "    \n",
    "    \n",
    "    accuracy = 100*correct/total\n",
    "    print(\"Test Accuracy: {}\".format(accuracy))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def get_data_loader(data, label, flag):\n",
    "    \"\"\"\n",
    "    returns train/test/val dataloaders\n",
    "    params: flag = train/test/val\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = DatasetLoader(data[flag], label[flag], transform=torchvision.transforms.ToTensor()) \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bronze-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    data, labels = load_dataset(\"segmentation\")\n",
    "    train_loader = get_data_loader(data, labels, \"train\")\n",
    "    val_loader = get_data_loader(data, labels,\"val\")\n",
    "    test_loader = get_data_loader(data, labels,\"test\")\n",
    " \n",
    "    # train model\n",
    "    losses, accuracies, model = train_model(train_loader, val_loader)\n",
    "    \n",
    "#     # plot trained metrics\n",
    "#     loss_curve = \"loss\"\n",
    "#     draw_training_curves(losses[0], losses[1],loss_curve)\n",
    "#     acc_curve = \"accuracy\"\n",
    "#     draw_training_curves(accuracies[0], accuracies[1] ,acc_curve)\n",
    "    \n",
    "#     # inference on test data and results\n",
    "#     create_confusion_matrix(model, val_loader)\n",
    "    \n",
    "#     # save the final model\n",
    "#     torch.save(model.state_dict(), CHECKPOINT_DIR + \"/cnn_model_final_\" + str(EPOCHS) + \".pth\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broad-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1\n",
      "torch.Size([8, 13, 384, 288]) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e08f193b3f1d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     # plot trained metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-25be8d709651>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainloader, valloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepoch_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-63307937c690>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, tloader, vloader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-bernard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-legend",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

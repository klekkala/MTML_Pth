{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "from scipy import io\n",
    "import torchsummary\n",
    "from load_scannet_vp_dataset import load_dataset\n",
    "from EarlyStopping import EarlyStopping\n",
    "import time\n",
    "# Constant variables\n",
    "EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.01  \n",
    "EVAL = True\n",
    "in_features = 131072\n",
    "# Paths\n",
    "\n",
    "CHECKPOINT_DIR = '/home4/shubham/MTML_Pth/checkpoints/vanishing_points'\n",
    "VIS_RESULTS_PATH = '/home4/shubham/MTML_Pth/results/vanishing_points'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG16Model,self).__init__()\n",
    "    \n",
    "        self.vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "        self.vgg16 = self.vgg16.features\n",
    "\n",
    "        for params in self.vgg16.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(in_features, 4096),\n",
    "                    nn.BatchNorm1d(4096),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(4096, 1024),\n",
    "                    nn.BatchNorm1d(1024),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(1024, 9)\n",
    "                )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \n",
    "        features = self.vgg16(image)\n",
    "        scores = self.head(features)\n",
    "        return scores\n",
    "\n",
    "# model = VGG16Model().to(DEVICE)\n",
    "# summary(model, (3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, image, v_points, transform = None):\n",
    "        self.image = image\n",
    "        self.v_points = v_points\n",
    "        self.length = len(image)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        classes = []\n",
    "        \n",
    "        image = Image.open(self.image[idx])\n",
    "        vps = np.load(self.v_points[idx])\n",
    "        classes.extend(vps['x'])\n",
    "        classes.extend(vps['y'])\n",
    "        classes.extend(vps['z'])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "            \n",
    "        return image, np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(model, trainloader, testloader, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    returns loss and accuracy of the model for 1 epoch.\n",
    "    params: model -  vgg16\n",
    "          trainloader - train dataset\n",
    "          testloader - test dataset\n",
    "          criterion - loss function\n",
    "          optimizer - Adam optimizer\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_epoch_accuracy = 0\n",
    "\n",
    "    test_epoch_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for image, points in trainloader:\n",
    "        image = image.to(DEVICE)\n",
    "        points = points.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        loss = criterion(output.float(), points.float())\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_epoch_loss = np.average(train_losses)\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, points in testloader:\n",
    "            image = image.to(DEVICE)\n",
    "            points = points.to(DEVICE)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output.float(), points.float())\n",
    "            test_losses.append(loss.item())\n",
    "     \n",
    "\n",
    "    test_epoch_loss = np.average(test_losses)\n",
    "        \n",
    "    \n",
    "    return train_epoch_loss, test_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainloader, testloader):\n",
    "    \"\"\"\n",
    "    returns losses (train and val), accuracies (train and val), trained_model\n",
    "    params: trainloader = train dataset\n",
    "            testloader = validation dataset\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    model = VGG16Model().to(DEVICE)\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    \n",
    "    early_stop = EarlyStopping(patience=PATIENCE,path=CHECKPOINT_DIR+'/early_stopping_vgg16_model.pth')\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"Running Epoch {}\".format(epoch+1))\n",
    "        start = time.time()\n",
    "        epoch_train_loss, epoch_test_loss = train_loop(model, trainloader, testloader, criterion, optimizer)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "\n",
    "        print(\"Time taken: {:.2f}\".format((time.time()-start)/60.))\n",
    "        print(\"Training loss: {0:.4f}  Testing loss: {1:0.4f}\".format(epoch_train_loss, epoch_test_loss))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        \n",
    "        early_stop(epoch_test_loss, model)\n",
    "    \n",
    "        if early_stop.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            flag = True\n",
    "            break\n",
    "        \n",
    "        if (epoch+1)%5 == 0:\n",
    "            torch.save(model.state_dict(), CHECKPOINT_DIR + \"/vgg16_epoch_\" + str(epoch+1) + \".pth\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    losses = [train_loss, test_loss]\n",
    " \n",
    "    \n",
    "    return losses, model, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "def draw_training_curves(train_losses, test_losses, curve_name):\n",
    "    \"\"\"\n",
    "    plots training and testing loss/accuracy curves\n",
    "    params: train_losses = training loss\n",
    "            test_losses = validation loss\n",
    "            curve_name = loss or accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.clf()\n",
    "        \n",
    "    plt.xlim([0,EPOCHS])\n",
    "    plt.plot(train_losses, label='Training {}'.format(curve_name))\n",
    "    plt.plot(test_losses, label='Testing {}'.format(curve_name))\n",
    "    plt.legend(frameon=False)\n",
    "    plt.savefig(VIS_RESULTS_PATH + \"/{}_vgg16.png\".format(curve_name))\n",
    "\n",
    "\n",
    "    \n",
    "def get_transformations(flag):\n",
    "    \"\"\"\n",
    "    returns series of augmentations and transformations\n",
    "    params: flag = train/test\n",
    "    \"\"\"\n",
    "    transfrms = []\n",
    "        \n",
    "    if flag == \"train\":\n",
    "        transfrms.append(torchvision.transforms.ColorJitter((1.2, 2.0)))\n",
    "        transfrms.append(torchvision.transforms.RandomHorizontalFlip(p=0.5))\n",
    "        \n",
    "    transfrms.append(torchvision.transforms.ToTensor())   \n",
    "    \n",
    "    return torchvision.transforms.Compose(transfrms)\n",
    "\n",
    "\n",
    "def get_data_loader(train_dataset, test_dataset):\n",
    "    \"\"\"\n",
    "    returns train/test/val dataloaders\n",
    "    \"\"\"\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "    testloader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return trainloader, testloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transformation = get_transformations(\"train\")\n",
    "test_transformation = get_transformations(\"test\")\n",
    "\n",
    "data, label = load_dataset()\n",
    "\n",
    "\n",
    "if EVAL:\n",
    "    train_dataset = DatasetLoader(data['train'], label['train'], train_transformation)\n",
    "    test_dataset = DatasetLoader(data['val'], label['val'], test_transformation)\n",
    "else:\n",
    "    train_dataset = DatasetLoader(data['train'] + data['val'], label['train'] + label['val'], train_transformation)\n",
    "    test_dataset = DatasetLoader(data['test'], label['test'], test_transformation)\n",
    "    \n",
    "\n",
    "train_loader, test_loader = get_data_loader(train_dataset, test_dataset)\n",
    "\n",
    "    \n",
    "# train model\n",
    "losses, accuracies, model = train_model(train_loader, val_loader)\n",
    "\n",
    "# # plot trained metrics\n",
    "# loss_curve = \"loss\"\n",
    "# draw_training_curves(losses[0], losses[1],loss_curve)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-remainder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-shuttle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-mitchell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

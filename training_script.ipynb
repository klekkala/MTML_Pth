{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "black-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from networks import SegNet\n",
    "\n",
    "# Constant variables\n",
    "EPOCHS = 100\n",
    "DEVICE = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.001\n",
    "INPUT_CHANNELS = 3\n",
    "OUTPUT_CHANNELS = 14\n",
    "IMG_SIZE = (288, 384)\n",
    "# Paths\n",
    "\n",
    "TRAIN_RGB_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/train_rgb/\"\n",
    "TRAIN_SEG_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/train_seg13/\"\n",
    "\n",
    "TEST_RGB_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/test_rgb/\"\n",
    "TEST_SEG_PATH = \"/home/shubham/MTML_Pth/pytorch-nyuv2/nyuv2/test_seg13/\"\n",
    "\n",
    "CHECKPOINT_DIR = '/home/shubham/MTML_Pth/checkpoints/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "supposed-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(flag):\n",
    "    \"\"\"\n",
    "    returns dictionary of images and their corresponding annotations split into train, val and test\n",
    "    :params: flag - (task) segmentation, depth or surface normal\n",
    "    \"\"\" \n",
    "    data = {}\n",
    "    label = {}\n",
    "    \n",
    "    TRAIN_PATH_IMG = None\n",
    "    TRAIN_PATH_LAB = None\n",
    "    TEST_PATH_IMG = None\n",
    "    TEST_PATH_LAB = None\n",
    "    \n",
    "    if flag == \"segmentation\":\n",
    "        TRAIN_PATH_IMG =  TRAIN_RGB_PATH\n",
    "        TRAIN_PATH_LAB = TRAIN_SEG_PATH\n",
    "        TEST_PATH_IMG = TEST_RGB_PATH\n",
    "        TEST_PATH_LAB = TEST_SEG_PATH\n",
    "        \n",
    "    elif flag == \"depth\":\n",
    "        TRAIN_PATH_IMG = None\n",
    "        TRAIN_PATH_LAB = None # fill in later\n",
    "        \n",
    "    train_images = glob.glob(TRAIN_PATH_IMG + \"*.png\")\n",
    "    train_labels = glob.glob(TRAIN_PATH_LAB + \"*.png\")\n",
    "    \n",
    "    index = np.random.permutation(len(train_images))\n",
    "    images = np.array(train_images)[index]\n",
    "    labels = np.array(train_labels)[index]\n",
    "    \n",
    "    length = int(len(images)*0.85)\n",
    "   \n",
    "    data[\"train\"], data[\"val\"] = images[:length], images[length:]\n",
    "    label[\"train\"], label[\"val\"] = labels[:length], labels[length:]\n",
    "    data[\"test\"] = glob.glob(TEST_PATH_IMG + \"*.png\")\n",
    "    label[\"test\"] = glob.glob(TEST_PATH_LAB + \"*.png\")\n",
    "    \n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "authorized-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, data, ground_truth, transform = None):\n",
    "        self.data = data\n",
    "        self.gt = ground_truth\n",
    "        self.length = len(data)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx])\n",
    "        img = img.resize(IMG_SIZE, Image.BILINEAR)\n",
    "        img = np.array(img)\n",
    "        gt = Image.open(self.gt[idx])\n",
    "        gt = gt.resize(IMG_SIZE, Image.BILINEAR)\n",
    "        gt = np.array(gt)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "appointed-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, tloader, vloader, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    returns loss and accuracy of the model for 1 epoch.\n",
    "    params: model -  vgg16\n",
    "          tloader - train dataset\n",
    "          vloader - val dataset\n",
    "          criterion - loss function\n",
    "          optimizer - Adam optimizer\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    t_epoch_accuracy = 0\n",
    "\n",
    "    v_epoch_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for ind, (image, label) in enumerate(tloader):\n",
    "     \n",
    "        image = image.to(DEVICE)\n",
    "        label = label.type(torch.LongTensor)\n",
    "        label = label.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _= model(image)\n",
    "        loss = criterion(output, label)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    t_epoch_loss = np.average(train_losses)\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ind, (image, label) in enumerate(vloader):\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.type(torch.LongTensor)\n",
    "            label = label.to(DEVICE)\n",
    "            output,_ = model(image)\n",
    "            loss = criterion(output, label)\n",
    "            pred_values, predicted = torch.max(output, 1)\n",
    "            valid_losses.append(loss.item())\n",
    "            if ind == 0:\n",
    "                fig = plt.figure(figsize=(11,11))\n",
    "                ax = plt.subplot(1, 3, 1)\n",
    "                plt.imshow(image[0].cpu().numpy().transpose((1, 2, 0)))\n",
    "                ax = plt.subplot(1, 3, 2)\n",
    "                plt.imshow(label[0].cpu())\n",
    "                ax = plt.subplot(1, 3, 3)\n",
    "                plt.imshow(predicted[0].cpu())\n",
    "                plt.show()\n",
    "                fig2 = plt.figure(figsize=(11,11))\n",
    "                ax = plt.subplot(1, 3, 1)\n",
    "                plt.imshow(image[1].cpu().numpy().transpose((1, 2, 0)))\n",
    "                ax = plt.subplot(1, 3, 2)\n",
    "                plt.imshow(gt[1].cpu())\n",
    "                ax = plt.subplot(1, 3, 3) \n",
    "                plt.imshow(predicted[1].cpu())\n",
    "                plt.show()\n",
    "    \n",
    "    v_epoch_loss = np.average(valid_losses)\n",
    "        \n",
    "    \n",
    "    return t_epoch_loss, v_epoch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "parental-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainloader, valloader):\n",
    "    \"\"\"\n",
    "    returns losses (train and val), accuracies (train and val), trained_model\n",
    "    params: trainloader = train dataset\n",
    "            valloader = validation dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    model = SegNet(INPUT_CHANNELS, OUTPUT_CHANNELS).to(DEVICE)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"Running Epoch {}\".format(epoch+1))\n",
    "\n",
    "        epoch_train_loss,  epoch_val_loss = train_loop(model, trainloader, valloader, criterion, optimizer)\n",
    "        train_loss.append(epoch_train_loss)   \n",
    "        val_loss.append(epoch_val_loss)\n",
    "  \n",
    "\n",
    "        print(\"Training loss: {:.4f}\".format(epoch_train_loss))\n",
    "        print(\"Validation loss: {:.4f}\".format(epoch_val_loss))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        \n",
    "        \n",
    "        if (epoch+1)%5 == 0:\n",
    "            torch.save(model.state_dict(), CHECKPOINT_DIR + \"/segnet_epoch_\" + str(epoch+1) + \".pth\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    losses = [train_loss, val_loss]\n",
    "    accuracies = [train_acc, val_acc]\n",
    "    \n",
    "    return losses, accuracies, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "animal-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, testloader):\n",
    "    \"\"\"\n",
    "    returns performance of the model on test dataset\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ind, (image, label) in enumerate(testloader):\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE, dtype=torch.long)\n",
    "\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted==label).sum().item()\n",
    "    \n",
    "    \n",
    "    accuracy = 100*correct/total\n",
    "    print(\"Test Accuracy: {}\".format(accuracy))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def get_data_loader(data, label, flag):\n",
    "    \"\"\"\n",
    "    returns train/test/val dataloaders\n",
    "    params: flag = train/test/val\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = DatasetLoader(data[flag], label[flag], transform=torchvision.transforms.ToTensor()) \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adequate-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    data, labels = load_dataset(\"segmentation\")\n",
    "    train_loader = get_data_loader(data, labels, \"train\")\n",
    "    val_loader = get_data_loader(data, labels,\"val\")\n",
    "    test_loader = get_data_loader(data, labels,\"test\")\n",
    " \n",
    "    # train model\n",
    "    losses, accuracies, model = train_model(train_loader, val_loader)\n",
    "    \n",
    "#     # plot trained metrics\n",
    "#     loss_curve = \"loss\"\n",
    "#     draw_training_curves(losses[0], losses[1],loss_curve)\n",
    "#     acc_curve = \"accuracy\"\n",
    "#     draw_training_curves(accuracies[0], accuracies[1] ,acc_curve)\n",
    "    \n",
    "#     # inference on test data and results\n",
    "#     create_confusion_matrix(model, val_loader)\n",
    "    \n",
    "#     # save the final model\n",
    "#     torch.save(model.state_dict(), CHECKPOINT_DIR + \"/cnn_model_final_\" + str(EPOCHS) + \".pth\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-alpha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
